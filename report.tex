\documentclass[a4paper, 12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[swedish,british]{babel}
\usepackage{fancyhdr}
\usepackage{listings} 

\pagestyle{fancy}
\title{Integer Factorization}
\author{Diana Gren \\ Jonas Carlsson \\\\ DD2440 Advanced Algorithms \\ Stefan Nilsson}
\date{}

\begin{document}
\maketitle
\tableofcontents
\newpage
\chapter{Background}
Factorize integers into prime numbers is considered a difficult problem. There is algorithms that solve the problem, but they can in some cases be very time consuming. An example is a product of two large prime numbers, which is very difficlt to factorize. This is the key in RSA cryptography, which completely relies on the fact that factoring products of large prime numbers is incredibly difficult.

\section{Algorithms}
As mentioned above, there are some algorithms that solve the problem, of which two of them will be discussed in this section.

\subsection{Trial Division}
\subsubsection{Method}
The most straight forward way of solving this problem is of course to divide a given number \emph{N} with each prime number up to $ \sqrt{N} $. If we find a prime $x$ such that
\begin{equation}
x \equiv 0 \pmod b
\end{equation}
we have found two factors. The first factor being $x$ and the second being $ \frac{N}{x} $.

\subsubsection{Performance}
Trial division is not an ideal approach as it is a heavy algortihm. It can, however, find a small factor fast if such a factor exists. Since there is a 50\% chance that a large $N$ is even, and 33\% that it has a factor 3 and so on, it can be a good idea to check for small prime numbers as factors.

\subsection{Fermat's Factorization Method}
\subsubsection{Method}
A simple way of improving the naive method is to use the fact that every odd number number $N$ can be represented as a difference of squares (proof in section \ref{sec:fermatproof}.
\begin{equation}
N = a^2 - b^2
\end{equation}
If we know $a$ and $b$, $N$ can easily be factored into two factors according to mathematical laws
\begin{equation}
N = a^2 - b^2 = (a + b)(a - b)
\end{equation}

To find such integers, one starts with an $x_0 = \lceil \sqrt{N} \rceil $. Check if 
\begin{equation}
\Delta x_0 = x_0^2 - N
\end{equation}
is a square number. If it is not, try next; $x_1 = x_0 + 1$
\begin{equation}
\Delta x_1 = x_1^2 - N
\end{equation}
etc. Do the same step, increasing $x$ by one, until a square number $ \Delta x $ is found.

\subsubsection{Performance}
Fermat's factorization method works well when the resulting factors ara of similar size. If that is not the case, this method is not optimal. However, the method sets base for more advance and better performing algorithms such as the \emph{quadratic sieve} and \emph{general number field sieve}

\subsection{Pollard Rho}
Pollard Rho is a fairly easy algorithm to both understand and implement, and it has an acceptable performance. The algorithm was invented by John Pollard in 1975, and its speciality is to factor composite numbers with small factors.


\chapter{Approach}
We decided to do the programming in C++. We both had limited knowledge in the language and wanted to learn more, as well as handling I/O for Kattis felt like a much easier task in C++ than in Java. 

Our approach for solving the problem was to implement the Pollard Rho algorithm. We did some research on the Quadratic Sieve, but ended up with Pollard Rho mostly because it is an easy algorithm, and at the same time it can perform quite well. We tested it towards Kattis, and tried to optimize it in different ways and in this chapter, we will discuss more into detail what was tested.

\section{Pollard Rho}
\subsection{Implementation}

We quickly realized that we needed the program to stop looking for factors if it was taking too long, so we introduced a cut off limit. The cut off limit is a limit for the maximum number of iterations the algorithm is allowed to do, and gives the answer "fail" if it did not succeed in fatorizing the given number. 

The scores could be improved just by increasing the cut off limit so that the program would run for as close to 15 seconds as possible, since it obviously had time to evaluate more numbers.

\begin{lstlisting}[frame=single] 
f(z, N)
	return z*z % N
function pollard(N) 
	x := random(N) 
	y := x 	
	prod := 1

	for i := 1 to infinity do
		x = f(x, N)
		y = f(f(y, N), N)

		if (x - y = 0) then
			prod = prod *(x-y) % N
			d := gcd(N, prod)

		if d > 1 and d < N then
			return d

		if i >= CUT_OFF_LIMIT then
			return 0
	end for
end function
\end{lstlisting}

\subsection{Optimizations}
We recognized that since there is a 50/50 chance that the given number is even, it could be a good idea to check that before running the algorithm, and thereby eliminate calculation time. So we started off by introducing a check for even numbers, and just return true if the condition was satisfied.

After reading more on Pollard Rho, we found that finding the greatest common divisor is quite expensive to do, hence we do not want to do that so often. This made us multiply the value a certain number of times before entering the gcd, hoping to improve the algorithm.

\section{Pollard Rho with Brent}
Pollard-Rho is a great algorithm but it suffers from one flaw. It can't handle a cyclic behaviour. With a cyclic behaviour i mean the function f produces repeated results. We can take an example from our own pollard-rho function. When we tried to factor 25 we got this sequence:
$a_1=1, a_2=22, a_3=16, a_4=2, a_5=19, a_6=7, a_7=2, a_8=19, a_9=7, a_10=2 ...$
Where a is the value to be investigated with GCD. This sequence will go nowhere and we will have to abort this run.

\subsection{Implementation}
Cycle finding can be implemented with either Floyds \"tortoise and hare algorithm\" or with Brents improvement. We choose to implement Brents but we shall start by discussing Floyds. Floyds algorithm builds upon the idea that for a sequence S, where S is built upon iterated functions. An important insight is that for integers $i ≥ μ$ and $k ≥ 0, x_i = x_{i + kλ}$, where λ is the length of the loop. Especially when $i = kλ >= μ$, it follows that $x_i = x_{2i}$.

\begin{lstlisting}
f(z, N)
	return z*z % N
function pollard_breant(N)
	y:=x0, r:=1, q:=1;
	while (G = 1)
		x=y;
		for i:=1 to r do y:=f(y,N), k:= 0
			while (k>=r) or (G>1)
				ys := y
				for i:=0 to min(m, r-k) do
					y:= f(y); q = (q * |x-y|) mod N
				end
			end
			G := GCD(q,N); k:=k+m
		end
		r=r*2
	end
	if G = N then
		while g = 1 do
			ys = f(ys,N); G= GCD(|x-y|, N)
		end
	end
	if G = n then success else fail
end
\end{lstlisting}
\subsection{Problems}
Finding information on how to implement pollard-rho with brent proved hard as the general information we found was for the cycle finding algorithm. We did not find any information to the combined version of pollard-brent at first. But later we found the the paper that brent himself published. Which resulted in the current iteration of our code.
\chapter{Results}

\begin{tabular} {c c c}
Cut off limit 	&	 Score 	& Time [s] \\ \hline
130		&	12		& 1.2 \\
1000	&	15		& 2.4 \\
10000 	& 	32		& 12.1 \\
12500	&	39		&14.20 \\

\end{tabular}
\chapter{Conclusion}
\appendix
\chapter{Algorithms}
\section{Fermat Difference of Squares}
\label{sec:fermatproof}
\begin{description}
\item{\bf Theorem:} An odd integer $N$ can be represented as a difference of squares $N = a^2 - b^2$.


\item{\bf Proof:} \\
Let $ N = m_1m_2 $, with $ m_1 \le m_2 $. Since we know that $N$ is odd, $m_1$ and $m_2$ must both be odd as well.

Let $ a = \frac{1}{2} (m_2 + m_1) $ and $ b = \frac{1}{2} (m_2 - m_1) $. Since both $m_1$ and $m_2$ are odd, both $a$ and $b$ will be integers. 

This gives us $m_1 = a - b$ and $m_2 = a + b $, hence $N = m_1m_2 = (a - b)(a + b) = a^2 - b^2$.

\end{description}
\end{document}